{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_training_complete = pd.read_csv(r'AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>2.520000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>103.794375</td>\n",
       "      <td>105.278949</td>\n",
       "      <td>102.228859</td>\n",
       "      <td>103.814702</td>\n",
       "      <td>103.463032</td>\n",
       "      <td>1.512050e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.087922</td>\n",
       "      <td>24.133609</td>\n",
       "      <td>23.659915</td>\n",
       "      <td>23.882168</td>\n",
       "      <td>23.998111</td>\n",
       "      <td>6.862665e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>57.020000</td>\n",
       "      <td>57.125000</td>\n",
       "      <td>53.152500</td>\n",
       "      <td>56.092499</td>\n",
       "      <td>55.661041</td>\n",
       "      <td>4.669130e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>80.093750</td>\n",
       "      <td>80.860001</td>\n",
       "      <td>79.259373</td>\n",
       "      <td>80.298752</td>\n",
       "      <td>79.896794</td>\n",
       "      <td>1.030439e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>113.047501</td>\n",
       "      <td>115.115002</td>\n",
       "      <td>110.593750</td>\n",
       "      <td>112.773751</td>\n",
       "      <td>112.411549</td>\n",
       "      <td>1.347102e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>122.829998</td>\n",
       "      <td>124.895626</td>\n",
       "      <td>120.917499</td>\n",
       "      <td>122.975002</td>\n",
       "      <td>122.791516</td>\n",
       "      <td>1.808931e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>143.600006</td>\n",
       "      <td>145.089996</td>\n",
       "      <td>141.369995</td>\n",
       "      <td>143.160004</td>\n",
       "      <td>142.946396</td>\n",
       "      <td>4.184740e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open        High         Low       Close   Adj Close  \\\n",
       "count  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
       "mean   103.794375  105.278949  102.228859  103.814702  103.463032   \n",
       "std     24.087922   24.133609   23.659915   23.882168   23.998111   \n",
       "min     57.020000   57.125000   53.152500   56.092499   55.661041   \n",
       "25%     80.093750   80.860001   79.259373   80.298752   79.896794   \n",
       "50%    113.047501  115.115002  110.593750  112.773751  112.411549   \n",
       "75%    122.829998  124.895626  120.917499  122.975002  122.791516   \n",
       "max    143.600006  145.089996  141.369995  143.160004  142.946396   \n",
       "\n",
       "             Volume  \n",
       "count  2.520000e+02  \n",
       "mean   1.512050e+08  \n",
       "std    6.862665e+07  \n",
       "min    4.669130e+07  \n",
       "25%    1.030439e+08  \n",
       "50%    1.347102e+08  \n",
       "75%    1.808931e+08  \n",
       "max    4.184740e+08  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_training_complete.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>70.570000</td>\n",
       "      <td>75.360001</td>\n",
       "      <td>69.430000</td>\n",
       "      <td>74.702499</td>\n",
       "      <td>74.127892</td>\n",
       "      <td>341397200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>75.917503</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>71.449997</td>\n",
       "      <td>72.330002</td>\n",
       "      <td>71.773636</td>\n",
       "      <td>319475600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>74.110001</td>\n",
       "      <td>75.849998</td>\n",
       "      <td>73.282501</td>\n",
       "      <td>75.684998</td>\n",
       "      <td>75.102829</td>\n",
       "      <td>219178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>73.879997</td>\n",
       "      <td>74.887497</td>\n",
       "      <td>72.852501</td>\n",
       "      <td>73.230003</td>\n",
       "      <td>72.666725</td>\n",
       "      <td>187572800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>72.705002</td>\n",
       "      <td>70.307503</td>\n",
       "      <td>72.257500</td>\n",
       "      <td>71.701706</td>\n",
       "      <td>226176800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2020-03-02  70.570000  75.360001  69.430000  74.702499  74.127892   \n",
       "1  2020-03-03  75.917503  76.000000  71.449997  72.330002  71.773636   \n",
       "2  2020-03-04  74.110001  75.849998  73.282501  75.684998  75.102829   \n",
       "3  2020-03-05  73.879997  74.887497  72.852501  73.230003  72.666725   \n",
       "4  2020-03-06  70.500000  72.705002  70.307503  72.257500  71.701706   \n",
       "\n",
       "      Volume  \n",
       "0  341397200  \n",
       "1  319475600  \n",
       "2  219178400  \n",
       "3  187572800  \n",
       "4  226176800  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_training_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_training_processed = apple_training_complete.iloc[:, 1:2].values #取第二列作为特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_training_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.57])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_training_processed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "apple_training_scaled = scaler.fit_transform(apple_training_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 1)\n",
      "0.2542735328523771\n",
      "[0.25427353]\n"
     ]
    }
   ],
   "source": [
    "print(apple_training_scaled.shape)\n",
    "print(apple_training_scaled[60, 0])\n",
    "print(apple_training_scaled[60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM\n",
    "\n",
    "## 1.\n",
    "(seq_len, batch, input_size)\n",
    "\n",
    "\n",
    "seq_len: is indeed the length of the sequence such as the number of words in a sentence or the number of characters in a string. \n",
    "input_size: reflects the number of features. \n",
    "\n",
    "本案例中要用过去60天的sample预测当前的value，所以seq_len为60\n",
    "\n",
    "## 2.\n",
    "h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2, else it should be 1.\n",
    "\n",
    "c_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial cell state for each element in the batch.\n",
    "\n",
    "If (h_0, c_0) is not provided, both h_0 and c_0 default to zero.\n",
    "\n",
    "h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
    "\n",
    "Like output, the layers can be separated using h_n.view(num_layers, num_directions, batch, hidden_size) and similarly for c_n.\n",
    "\n",
    "c_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the cell state for t = seq_len."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.8\n",
    "batch_size = 20\n",
    "epoch_size = 50\n",
    "lr = 1e-3\n",
    "seq_len = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.f1 = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.f2 = nn.LSTM(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.f3 = nn.LSTM(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.f4 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1, (h_n, h_c) = self.f1(x, None) #(h0, c0)初始化为0\n",
    "        out2, (h_n, h_c) = self.f2(out1, None)\n",
    "        out3, (h_n, h_c) = self.f3(out2, None)\n",
    "        out = self.f4(out3[:, -1, :])#忘加f2\n",
    "        return out#忘记return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([192, 60, 1]) [192个sample, 过去的60个时间点组成一个sequence，每个时间点取1个特征]\n"
     ]
    }
   ],
   "source": [
    "features_set, labels = [], []\n",
    "for i in range(seq_len, apple_training_scaled.shape[0]):\n",
    "    features_set.append(apple_training_scaled[i-seq_len:i, 0]) #当前label的值取决于label前60天的股票值\n",
    "    labels.append(apple_training_scaled[i, 0])\n",
    "features_set, labels = np.array(features_set), np.array(labels)\n",
    "#print(features_set.shape, labels.shape)\n",
    "features_set = features_set.astype(np.float32)\n",
    "labels = labels.astype(np.float32)\n",
    "features_set = torch.from_numpy(features_set)\n",
    "labels = torch.from_numpy(labels)\n",
    "\n",
    "#features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n",
    "features_set = features_set.view(features_set.shape[0], features_set.shape[1], 1)\n",
    "print(features_set.shape, \"[192个sample, 过去的60个时间点组成一个sequence，每个时间点取1个特征]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(features_set.shape[0] * valid_ratio)\n",
    "features_train, labels_train = features_set[ : train_num], labels[ : train_num]\n",
    "features_test, labels_test = features_set[train_num : ], labels[train_num : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (f1): LSTM(1, 50, batch_first=True)\n",
      "  (f2): LSTM(50, 50, batch_first=True)\n",
      "  (f3): LSTM(50, 50, batch_first=True)\n",
      "  (f4): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Data.TensorDataset(features_train, labels_train)\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = RNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99))\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "#print(\"| features_set: {:} | labels: {:}\".format(features_set.shape, labels.shape))\n",
    "#for x_train, x_label in train_loader:\n",
    "#    print(\"| x_train: {:}       | x_label: {:}\".format(x_train.shape, x_label.shape))\n",
    "#    break\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train LSTM on our data, we need to convert our data into the shape accepted by the LSTM. We need to convert our data into three-dimensional format. The first dimension is the number of records or rows in the dataset which is batch_size in our case. The second dimension is the number of time steps which is 60 while the last dimension is the number of indicators. Since we are only using one feature, i.e Open, the number of features indicators will be one. Execute the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_record = []\n",
    "rmse_record = []\n",
    "for epoch in range(epoch_size):\n",
    "    loss_epoch = 0\n",
    "    for x_train, x_label in train_loader:\n",
    "        x_train = x_train.view(x_train.shape[0], -1, 1)\n",
    "        output = model(x_train)\n",
    "        #print(output.view(-1).shape, x_label.shape)\n",
    "        #print(output.shape, labels.shape)\n",
    "        loss_batch = loss_func(output.view(-1), x_label)\n",
    "        loss_epoch = loss_epoch + loss_batch\n",
    "        optimizer.zero_grad()\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "    loss_record.append(loss_epoch.data.numpy())\n",
    "    with torch.no_grad():\n",
    "        output = model(features_test.view(features_test.shape[0], -1, 1))\n",
    "        rmse = loss_func(output.view(-1), labels_test)\n",
    "        rmse_record.append(rmse.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def show_loss_rmse(loss_his, rmse_his, dataname):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    \n",
    "    x_loss = range(len(loss_his))\n",
    "    ax1.plot(x_loss, loss_his, label='loss', color = 'g', linewidth=2)\n",
    "    ax1.set_xlabel('iteration')\n",
    "    ax1.set_ylabel('loss')\n",
    "    #ax1.set_facecolor('lightsteelblue')\n",
    "    ax1.grid(b=True, color='gray', linestyle='--', linewidth=1, alpha=0.8)\n",
    "    ax1.legend()\n",
    "    \n",
    "    x_rmse = range(len(rmse_his))\n",
    "    ax2.plot(x_rmse, rmse_his, label='rmse', color = 'r', linewidth=2)\n",
    "    ax2.set_xlabel('iteration')\n",
    "    ax2.set_ylabel('rmse')\n",
    "    ax2.grid(b=True, color='gray', linestyle='--', linewidth=1, alpha=0.8)\n",
    "    ax2.legend()\n",
    "    \n",
    "    #plt.savefig(\"./Results/images/test_nmf_\" + dataname + \".png\", dpi=750, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_loss_rmse(loss_record, rmse_record, \"apple_stock_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042036287 0.00552317\n"
     ]
    }
   ],
   "source": [
    "print(loss_record[-1], rmse_record[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 10, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of Sequence Length to Prediction (accuracy measured by rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_training_complete = pd.read_csv(r'AAPL.csv')\n",
    "apple_training_processed = apple_training_complete.iloc[:, 1:2].values #取第二列作为特征\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "apple_training_scaled = scaler.fit_transform(apple_training_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.f1 = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.f2 = nn.LSTM(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.f3 = nn.LSTM(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.f4 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1, (h_n, h_c) = self.f1(x, None) #(h0, c0)初始化为0\n",
    "        out2, (h_n, h_c) = self.f2(out1, None)\n",
    "        out3, (h_n, h_c) = self.f3(out2, None)\n",
    "        out = self.f4(out3[:, -1, :])#忘加f2\n",
    "        return out#忘记return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_features(seq_len):\n",
    "    features_set, labels = [], []\n",
    "    for i in range(seq_len, apple_training_scaled.shape[0]):\n",
    "        features_set.append(apple_training_scaled[i-seq_len:i, 0]) #当前label的值取决于label前60天的股票值\n",
    "        labels.append(apple_training_scaled[i, 0])\n",
    "    features_set, labels = np.array(features_set), np.array(labels)\n",
    "    #print(features_set.shape, labels.shape)\n",
    "    features_set = features_set.astype(np.float32)\n",
    "    labels = labels.astype(np.float32)\n",
    "    features_set = torch.from_numpy(features_set)\n",
    "    labels = torch.from_numpy(labels)\n",
    "\n",
    "    features_set = features_set.view(features_set.shape[0], features_set.shape[1], 1)\n",
    "    return features_set, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.8\n",
    "batch_size = 20\n",
    "epoch_size = 30\n",
    "lr = 1e-3\n",
    "start_len = 55\n",
    "end_len = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length is: 55 | Loss: 0.04095 | Rmse: 0.005666\n",
      "Sequence Length is: 56 | Loss: 0.04425 | Rmse: 0.004134\n",
      "Sequence Length is: 57 | Loss: 0.05824 | Rmse: 0.004835\n",
      "Sequence Length is: 58 | Loss: 0.04247 | Rmse: 0.004072\n",
      "Sequence Length is: 59 | Loss: 0.06551 | Rmse: 0.004318\n",
      "Sequence Length is: 60 | Loss: 0.05615 | Rmse: 0.00776\n",
      "Sequence Length is: 61 | Loss: 0.04838 | Rmse: 0.00413\n",
      "Sequence Length is: 62 | Loss: 0.04681 | Rmse: 0.00412\n",
      "Sequence Length is: 63 | Loss: 0.05581 | Rmse: 0.004717\n",
      "Sequence Length is: 64 | Loss: 0.04944 | Rmse: 0.004749\n",
      "Sequence Length is: 65 | Loss: 0.05209 | Rmse: 0.006464\n"
     ]
    }
   ],
   "source": [
    "seq_len_list = list(range(start_len, end_len+1, 1)) #测试先验序列长度设为 55， 65之间时哪个预测的最准\n",
    "loss_compare, rmse_compare = [], []\n",
    "\n",
    "best_seq_len = start_len\n",
    "min_rmse = 1e9\n",
    "\n",
    "for seq_len in seq_len_list:\n",
    "\n",
    "    features_set, labels = get_sequence_features(seq_len)\n",
    "    train_num = int(features_set.shape[0] * valid_ratio)\n",
    "    features_train, labels_train = features_set[ : train_num], labels[ : train_num]\n",
    "    features_test, labels_test = features_set[train_num : ], labels[train_num : ]\n",
    "    \n",
    "    #print(features_train.shape, labels_train.shape, features_test.shape, labels_test.shape)\n",
    "    train_dataset = Data.TensorDataset(features_train, labels_train)\n",
    "    train_loader = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = RNN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99))\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    \n",
    "    loss_record = []\n",
    "    rmse_record = []\n",
    "    for epoch in range(epoch_size):\n",
    "        loss_epoch = 0\n",
    "        for x_train, x_label in train_loader:\n",
    "            x_train = x_train.view(x_train.shape[0], -1, 1)\n",
    "            output = model(x_train)\n",
    "            #print(output.view(-1).shape, x_label.shape)\n",
    "            #print(output.shape, labels.shape)\n",
    "            loss_batch = loss_func(output.view(-1), x_label)\n",
    "            loss_epoch += loss_batch\n",
    "            optimizer.zero_grad()\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "        loss_record.append(loss_epoch.data.numpy())\n",
    "        with torch.no_grad():\n",
    "            output = model(features_test.view(features_test.shape[0], -1, 1))\n",
    "            rmse = loss_func(output.view(-1), labels_test)\n",
    "            rmse_record.append(rmse.data.numpy())\n",
    "    \n",
    "    if rmse_record[-1] < min_rmse:\n",
    "        min_rmse = rmse_record[-1]\n",
    "        best_seq_len = seq_len\n",
    "        #print(min_rmse)\n",
    "\n",
    "    loss_compare.append(loss_record[-1])\n",
    "    rmse_compare.append(rmse_record[-1])\n",
    "    \n",
    "    print(\"Sequence Length is: {:} | Loss: {:4.4} | Rmse: {:4.4}\".format(seq_len, loss_record[-1], rmse_record[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Sequence Length For Predicting Stock Price of Apple is 58.\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Sequence Length For Predicting Stock Price of Apple is {:}.\".format(best_seq_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare different optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
